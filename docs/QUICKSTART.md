"""
QUICK START - 5 Minutes to AI Code Generation

Multi-Local AI Coders - Enterprise Edition
"""

# ============================================================
# QUICK START (Development)
# ============================================================

## 1. Install (1 min)

```bash
git clone https://github.com/your-org/multi-local-ai-coders.git
cd multi-local-ai-coders
pip install -r docs/requirements.txt
cp .env.example .env
```

## 2. Start Ollama (30 sec)

```bash
# Terminal 1
ollama serve

# Terminal 2
ollama pull qwen2:7b
```

## 3. Run Continue.dev Server (30 sec)

```bash
# Terminal 3
python run_server.py --env development

# Output:
# ============================================================
# Continue.dev Integration Server
# ============================================================
# Environment: development
# Host: 127.0.0.1
# Port: 8000
# ...
# API available at http://127.0.0.1:8000/api/v1
```

## 4. Test Locally (2 min)

```bash
# Terminal 4
# Test batch mode
python main.py "Create a Python function that validates email addresses"

# Or test API
curl -X POST http://localhost:8000/api/v1/chat \\
  -H "Content-Type: application/json" \\
  -d '{"message": "Generate Hello World in Python"}'
```

## 5. Configure VSCode (1 min)

Edit `.continue/config.json`:
```json
{
  "models": [
    {
      "provider": "openrouter",
      "model": "local",
      "apiBase": "http://127.0.0.1:8000/api/v1",
      "apiKey": "any-key"
    }
  ]
}
```

Press `Ctrl+L` in VSCode to open Continue chat!

# ============================================================
# KEY NEW FEATURES
# ============================================================

âœ¨ TIER 1 - Multi-Language Enterprise Support
  â€¢ Support for 15+ programming languages (Python, TypeScript, Java, Go, Rust, etc)
  â€¢ Unified AST parsing with tree-sitter
  â€¢ Parallel step execution (30-40% faster)
  â€¢ Unified diagnostics (lint, type-check, security scan)
  â€¢ Exponential backoff retry logic

âœ¨ TIER 2 - Smart Context & Quality
  â€¢ Intelligent context windowing (respects token limits)
  â€¢ Semantic compression (multi-pass LLM summarization)
  â€¢ Project understanding (build system, entry points, patterns)
  â€¢ Knowledge graph (dependency tracking)
  â€¢ 6-criteria code review (functional, security, performance, etc)

âœ¨ TIER 3 - Production Continue.dev
  â€¢ JWT authentication + API keys
  â€¢ WebSocket streaming
  â€¢ Rate limiting (100 req/hour default)
  â€¢ Session persistence (Redis optional)
  â€¢ Structured logging + OpenTelemetry
  â€¢ Health checks & observability

# ============================================================
# PERFORMANCE
# ============================================================

Speed: 30-45 seconds per request (vs 45-70s baseline)
  â€¢ Project analysis: 2-3s (NEW)
  â€¢ Memory retrieval: 1-2s
  â€¢ Planning: 15-20s
  â€¢ Execution: 2-5s (now parallel!)
  â€¢ Review: 10-15s

Quality: Competing with Copilot for local inference
  â€¢ Multi-criteria code review
  â€¢ Security scanning (bandit, snyk, etc)
  â€¢ Performance analysis (Big-O complexity)
  â€¢ Test coverage recommendations

# ============================================================
# COMMON TASKS
# ============================================================

### Generate Code
```bash
python main.py "Generate a REST API endpoint for user login using FastAPI"
```

### Analyze File for Issues
```bash
python main.py "Find security vulnerabilities in src/api.py"
```

### Refactor Code
```bash
python main.py "Refactor src/utils.py to remove code duplication"
```

### Check Code Quality
```bash
python main.py "Review src/main.py for complexity and maintainability issues"
```

### Multi-Language Support
```bash
python main.py "Create an equivalent of this Python function in TypeScript"
# Works for any combo of 15+ languages!
```

# ============================================================
# DEVELOPMENT VS PRODUCTION
# ============================================================

### Development (local testing)
```bash
python run_server.py --env development
# - Auto-reload on code changes
# - Debug logging
# - No authentication required
# - Easier troubleshooting
```

### Production (deployment)
```bash
python run_server.py --env production
# - No auto-reload (stable)
# - Warning-level logging
# - JWT authentication required
# - Redis support enabled
# - Rate limiting enforced
```

# ============================================================
# WHAT'S DIFFERENT FROM BASELINE?
# ============================================================

Before (Baseline)
- Only Python language support
- Sequential execution
- Basic code review (3 criteria)
- No context management
- No production API
- ~70 second execution time

After (Enterprise Edition)
- 15+ languages supported
- Parallel execution where possible (+30-40% speed)
- 6 criteria code review (functional, security, performance, maintainability, testing, compliance)
- Smart context windowing + semantic compression
- Production-grade API (JWT, WebSocket, rate limiting)
- ~45 second execution time
- Observability (OpenTelemetry, structured logging)

# ============================================================
# FILE STRUCTURE (WHAT'S NEW)
# ============================================================

```
core/
  â”œâ”€ language_registry.py       [NEW] Language detection & config
  â”œâ”€ ast_parser.py              [NEW] Unified AST parsing
  â”œâ”€ language_server.py         [NEW] LSP abstraction
  â”œâ”€ diagnostics_engine.py      [NEW] Unified diagnostics
  â”œâ”€ observability.py           [NEW] OpenTelemetry setup
  â”œâ”€ structured_logger.py       [NEW] Structured logging
  â”œâ”€ context_manager.py         [NEW] Token budget management
  â”œâ”€ semantic_compression.py    [NEW] LLM-based compression
  â”œâ”€ project_analyzer.py        [NEW] Project understanding
  â”œâ”€ knowledge_graph.py         [NEW] Semantic graph
  â”œâ”€ chat_interface_v2.py       [NEW] Production Continue.dev API
  â”œâ”€ server_config.py           [NEW] Server configuration
  â””â”€ llm.py                     [UPDATED] Added exponential backoff

agents/
  â”œâ”€ executor_v2.py            [NEW] Parallel executor
  â”œâ”€ reviewer_v2.py            [NEW] Multi-criteria review
  â””â”€ executor.py               [OLD] Preserved for compatibility

tools/
  â”œâ”€ language_diagnostics_tool.py [NEW] Diagnostic runners

run_server.py                    [NEW] Server startup script
ENTERPRISE_GUIDE.md             [NEW] Complete documentation
QUICKSTART.md                   [NEW] This file
```

# ============================================================
# TROUBLESHOOTING
# ============================================================

**Q: Model seems slow**
A: Try smaller model: `ollama pull mistral:7b` (faster, less capable)
   Or larger: `ollama pull qwen2:14b` (slower, better quality)

**Q: "Connection refused" error**
A: Make sure Ollama is running: `ollama serve` in another terminal

**Q: Continue.dev won't connect**
A: Check `.continue/config.json` has correct API endpoint
   Default is `http://127.0.0.1:8000/api/v1`

**Q: Low quality code**
A: 1. Check model: `ollama list`
   2. Increase planning time (edit core/llm.py timeout)
   3. Use larger model (qwen2:14b)
   4. Provide more context in prompt

**Q: Server crashes**
A: Check logs: `tail -f logs/agent_*.json`
   Enable debug: `python run_server.py --env development`

# ============================================================
# NEXT STEPS
# ============================================================

1. âœ… Install & run this quickstart
2. âœ… Read ENTERPRISE_GUIDE.md for detailed features
3. âœ… Try different prompts and models
4. âœ… Configure Continue.dev for your workflow
5. ðŸ”„ Fine-tune prompts in prompts/ directory
6. ðŸ“Š Monitor performance with logs/agent_*.json
7. ðŸš€ Deploy to production when ready

# ============================================================
# SUPPORT & FEEDBACK
# ============================================================

Issues? Questions?
- Check logs: `logs/` directory
- Enable tracing: `CONTINUE_TRACING=true python run_server.py`
- Debug mode: `python run_server.py --env development`
- Review: ENTERPRISE_GUIDE.md, README.md

Ready to generate some amazing code! ðŸš€
